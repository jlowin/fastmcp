---
title: Prompts
description: Create reusable, parameterized message templates for LLMs.
---

import { VersionBadge } from "/snippets/version-badge.mdx"

Prompts give LLMs structured, reusable starting points for conversations. Unlike tools (which perform actions) or resources (which provide data), prompts shape how LLMs approach tasks by providing pre-defined message templates.

When a client requests a prompt, FastMCP validates the parameters against your function signature, executes the function, and returns the generated messages. This lets you define consistent conversation starters that work across different clients and contexts.

## Overview

Decorate any Python function with `@mcp.prompt` to expose it as a prompt. FastMCP extracts the name from your function, the description from your docstring, and builds the argument schema from your type annotations.

```python
from fastmcp import FastMCP

mcp = FastMCP(name="PromptServer")

@mcp.prompt
def ask_about_topic(topic: str) -> str:
    """Generates a user message asking for an explanation of a topic."""
    return f"Can you please explain the concept of '{topic}'?"
```

The way you write your Python function determines how the prompt appears to LLMs.

<Tip>
Functions with `*args` or `**kwargs` are not supported as prompts. FastMCP needs to generate a complete argument schema for MCP, which requires knowing all arguments at registration time.
</Tip>

### Decorator Arguments

Override inferred values or add metadata with decorator arguments:

```python
from pydantic import Field
from fastmcp import FastMCP

mcp = FastMCP(name="PromptServer")

@mcp.prompt(
    name="analyze_data_request",
    description="Creates a request to analyze data with specific parameters.",
    tags={"analysis", "data"},
    meta={"version": "1.1", "author": "data-team"},
)
def data_analysis_prompt(
    data_uri: str = Field(description="The URI of the resource containing the data."),
    analysis_type: str = Field(default="summary", description="Type of analysis."),
) -> str:
    """This docstring is ignored when description is provided."""
    return f"Please perform a '{analysis_type}' analysis on the data found at {data_uri}."
```

<Card icon="code" title="@prompt Decorator Arguments">
<ParamField body="name" type="str | None">
  Prompt name exposed via MCP. Defaults to the function name.
</ParamField>

<ParamField body="title" type="str | None">
  A human-readable title for the prompt.
</ParamField>

<ParamField body="description" type="str | None">
  Description exposed via MCP. Defaults to the function's docstring.
</ParamField>

<ParamField body="tags" type="set[str] | None">
  Categorization tags for filtering and organization.
</ParamField>

<ParamField body="icons" type="list[Icon] | None">
  <VersionBadge version="2.13.0" />
  Icon representations for this prompt. See [Icons](/servers/icons).
</ParamField>

<ParamField body="meta" type="dict[str, Any] | None">
  <VersionBadge version="2.11.0" />
  Custom metadata passed through to clients.
</ParamField>

<ParamField body="version" type="str | int | None">
  <VersionBadge version="3.0.0" />
  Version identifier. See [Versioning](/servers/versioning).
</ParamField>
</Card>

### Async Prompts

FastMCP supports both `async def` and regular `def` functions as prompts. Synchronous prompts run in a threadpool automatically, so they don't block the event loop.

```python
import aiohttp
from fastmcp import FastMCP

mcp = FastMCP(name="PromptServer")

@mcp.prompt
async def data_based_prompt(data_id: str) -> str:
    """Generates a prompt based on data that needs to be fetched."""
    async with aiohttp.ClientSession() as session:
        async with session.get(f"https://api.example.com/data/{data_id}") as response:
            data = await response.json()
            return f"Analyze this data: {data['content']}"
```

For I/O-bound operations like network requests or database queries, async prompts are more efficient than threadpool dispatch.

### Context Access

<VersionBadge version="2.2.5" />

Prompts can access MCP features through the `Context` object: logging, resource reading, and request metadata. Add a parameter with the `Context` type hint:

```python
from fastmcp import FastMCP, Context

mcp = FastMCP(name="PromptServer")

@mcp.prompt
async def generate_report_request(report_type: str, ctx: Context) -> str:
    """Generates a request for a report."""
    await ctx.info(f"Generating {report_type} report prompt")
    return f"Please create a {report_type} report. Request ID: {ctx.request_id}"
```

See [Context](/servers/context) for complete documentation on context capabilities and custom dependencies.

### Instance Methods

The `@mcp.prompt` decorator registers prompts immediately, which doesn't work with instance methods (you'd see `self` as a required argument). Use the standalone `@prompt` decorator to attach metadata, then register the bound method:

```python
from fastmcp import FastMCP
from fastmcp.prompts import prompt

class GreetingService:
    def __init__(self, greeting: str):
        self.greeting = greeting

    @prompt()
    def greet(self, name: str) -> str:
        """Generate a personalized greeting."""
        return f"{self.greeting}, {name}!"

service = GreetingService(greeting="Hello")
mcp = FastMCP()
mcp.add_prompt(service.greet)  # Schema shows only 'name', not 'self'
```

## Arguments

FastMCP converts Python function signatures into MCP prompt argument schemas. Type annotations determine argument types, defaults determine whether arguments are required, and Pydantic's `Field` adds descriptions.

### Required vs Optional

Arguments without default values are required. Arguments with default values are optional:

```python
from fastmcp import FastMCP

mcp = FastMCP()

@mcp.prompt
def data_analysis_prompt(
    data_uri: str,                   # Required
    analysis_type: str = "summary",  # Optional
    include_charts: bool = False,    # Optional
) -> str:
    """Creates a request to analyze data with specific parameters."""
    prompt = f"Please perform a '{analysis_type}' analysis on the data found at {data_uri}."
    if include_charts:
        prompt += " Include relevant charts and visualizations."
    return prompt
```

The client must provide `data_uri`. If `analysis_type` or `include_charts` are omitted, their default values are used.

### Argument Descriptions

Use Pydantic's `Field` to add descriptions that help LLMs understand what each argument expects:

```python
from pydantic import Field
from fastmcp import FastMCP

mcp = FastMCP()

@mcp.prompt
def code_review(
    code: str = Field(description="The source code to review"),
    language: str = Field(default="python", description="Programming language of the code"),
    focus: str = Field(default="general", description="Review focus: security, performance, or general"),
) -> str:
    """Generate a code review prompt."""
    return f"Review this {language} code with a focus on {focus}:\n\n```{language}\n{code}\n```"
```

| Field Option | Purpose |
| :----------- | :------ |
| `description` | Human-readable explanation shown to LLMs |
| `default` | Default value if argument is omitted |

### Complex Types

<VersionBadge version="2.9.0" />

The MCP specification requires all prompt arguments to be passed as strings, but FastMCP lets you use typed annotations for better developer experience. When you use complex types like `list[int]` or `dict[str, str]`, FastMCP automatically converts string arguments from MCP clients to the expected types and generates descriptions showing the required JSON format.

<CodeGroup>

```python Python Code
from fastmcp import FastMCP

mcp = FastMCP()

@mcp.prompt
def analyze_data(
    numbers: list[int],
    metadata: dict[str, str],
    threshold: float,
) -> str:
    """Analyze numerical data."""
    avg = sum(numbers) / len(numbers)
    return f"Average: {avg}, above threshold: {avg > threshold}"
```

```json Resulting MCP Prompt
{
  "name": "analyze_data",
  "description": "Analyze numerical data.",
  "arguments": [
    {
      "name": "numbers",
      "description": "Provide as a JSON string matching the following schema: {\"items\":{\"type\":\"integer\"},\"type\":\"array\"}",
      "required": true
    },
    {
      "name": "metadata",
      "description": "Provide as a JSON string matching the following schema: {\"additionalProperties\":{\"type\":\"string\"},\"type\":\"object\"}",
      "required": true
    },
    {
      "name": "threshold",
      "description": "Provide as a JSON string matching the following schema: {\"type\":\"number\"}",
      "required": true
    }
  ]
}
```

</CodeGroup>

MCP clients call this prompt with string arguments:

```json
{
  "numbers": "[1, 2, 3, 4, 5]",
  "metadata": "{\"source\": \"api\", \"version\": \"1.0\"}",
  "threshold": "2.5"
}
```

Direct calls with properly typed arguments also work:

```python
result = await prompt.render({
    "numbers": [1, 2, 3, 4, 5],
    "metadata": {"source": "api", "version": "1.0"},
    "threshold": 2.5,
})
```

<Warning>
Keep type annotations simple. Complex nested types or custom classes may not convert reliably from JSON strings. The auto-generated schema descriptions are the only guidance users receive about the expected format.

Good choices: `list[int]`, `dict[str, str]`, `float`, `bool`

Avoid: Complex Pydantic models, deeply nested structures, custom classes
</Warning>

### Type Reference

| Type Annotation | MCP Format | Description |
| :-------------- | :--------- | :---------- |
| `str` | String | Direct string value |
| `int`, `float` | JSON number string | `"42"`, `"3.14"` |
| `bool` | JSON boolean string | `"true"`, `"false"` |
| `list[T]` | JSON array string | `"[1, 2, 3]"` |
| `dict[K, V]` | JSON object string | `"{\"key\": \"value\"}"` |

## Results

FastMCP prompts can return simple strings, lists of messages, or full `PromptResult` objects with metadata. The return type determines how your response is formatted for the MCP client.

| Return Type | Description |
| :---------- | :---------- |
| `str` | Single user message |
| `list[Message \| str]` | Conversation sequence (strings auto-convert to user messages) |
| `PromptResult` | Full control over messages, description, and metadata |

### String Returns

The simplest prompts return a string, which becomes a single user message:

```python
from fastmcp import FastMCP

mcp = FastMCP()

@mcp.prompt
def ask_about_topic(topic: str) -> str:
    """Ask for an explanation of a topic."""
    return f"Can you please explain the concept of '{topic}'?"
```

### Message

<VersionBadge version="3.0.0" />

`Message` provides a user-friendly wrapper for prompt messages with automatic serialization. Strings pass through directly, while other types (dict, list, BaseModel) are JSON-serialized.

```python
from fastmcp.prompts import Message

# String content (user role by default)
Message("Hello, world!")

# Explicit role
Message("I can help with that.", role="assistant")

# Auto-serialized to JSON text
Message({"key": "value"})
Message(["item1", "item2"])
```

| Field | Type | Default | Description |
| :---- | :--- | :------ | :---------- |
| `content` | `Any` | required | The message content. Strings pass through directly. Other types (dict, list, BaseModel) are JSON-serialized. |
| `role` | `"user" \| "assistant"` | `"user"` | The message role. |

### Message Lists

Return a list of messages to create a conversation with multiple turns:

```python
from fastmcp import FastMCP
from fastmcp.prompts import Message

mcp = FastMCP()

@mcp.prompt
def roleplay_scenario(character: str, situation: str) -> list[Message]:
    """Sets up a roleplaying scenario with initial messages."""
    return [
        Message(f"Let's roleplay. You are {character}. The situation is: {situation}"),
        Message("Okay, I understand. I am ready. What happens next?", role="assistant"),
    ]

@mcp.prompt
def code_generation(language: str, task: str) -> list[Message]:
    """Generate a code request conversation."""
    return [
        Message(f"Write a {language} function that performs: {task}"),
        Message("I'll help you write that function.", role="assistant"),
    ]
```

Strings in the list are automatically converted to user messages, so you can mix strings and `Message` objects.

### PromptResult

<VersionBadge version="3.0.0" />

`PromptResult` gives you explicit control over prompt responses: multiple messages, roles, and metadata at both the message and result level.

```python
from fastmcp import FastMCP
from fastmcp.prompts import PromptResult, Message

mcp = FastMCP()

@mcp.prompt
def code_review(code: str) -> PromptResult:
    """Returns a code review prompt with metadata."""
    return PromptResult(
        messages=[
            Message(f"Please review this code:\n\n```\n{code}\n```"),
            Message("I'll analyze this code for issues.", role="assistant"),
        ],
        description="Code review prompt",
        meta={"review_type": "security", "priority": "high"},
    )
```

For simple cases, pass a string directly:

```python
return PromptResult("Please help me with this task")  # auto-converts to single Message
```

| Field | Type | Description |
| :---- | :--- | :---------- |
| `messages` | `str \| list[Message]` | Messages to return. Strings are wrapped as a single user Message. |
| `description` | `str \| None` | Optional description of the prompt result. Defaults to the prompt's docstring. |
| `meta` | `dict[str, Any] \| None` | Result-level metadata, included in the MCP response's `_meta` field. |

<Note>
The `meta` field in `PromptResult` is runtime metadata specific to this render response. The `meta` parameter in `@mcp.prompt(meta={...})` provides static metadata about the prompt definition itself (returned when listing prompts).
</Note>

### When to Use Each

| Approach | Use When |
| :------- | :------- |
| `str` | Simple single-message prompts |
| `list[Message]` | Multi-turn conversations or assistant pre-responses |
| `PromptResult` | You need to include runtime metadata or a custom description |

You can always return plain `str` or `list[Message]` from your prompt functions. `PromptResult` is opt-in for when you need metadata or explicit control.

## Visibility Control

<VersionBadge version="3.0.0" />

Control which prompts are visible to clients using server-level visibility. Disabled prompts don't appear in `list_prompts` and can't be called.

```python
from fastmcp import FastMCP

mcp = FastMCP("MyServer")

@mcp.prompt(tags={"public"})
def public_prompt(topic: str) -> str:
    return f"Discuss: {topic}"

@mcp.prompt(tags={"internal"})
def internal_prompt() -> str:
    return "Internal system prompt"

# Disable specific prompts by key
mcp.disable(keys=["prompt:internal_prompt"])

# Disable prompts by tag
mcp.disable(tags={"internal"})

# Or use allowlist mode - only show prompts with specific tags
mcp.enable(tags={"public"}, only=True)
```

See [Visibility](/servers/visibility) for the complete visibility control API.

## Notifications

<VersionBadge version="2.9.1" />

FastMCP automatically sends `notifications/prompts/list_changed` notifications to connected clients when prompts are added, enabled, or disabled. This allows clients to stay up-to-date with the current prompt set without polling.

```python
@mcp.prompt
def example_prompt() -> str:
    return "Hello!"

# These operations trigger notifications:
mcp.add_prompt(example_prompt)               # Sends prompts/list_changed notification
mcp.disable(keys=["prompt:example_prompt"])  # Sends prompts/list_changed notification
mcp.enable(keys=["prompt:example_prompt"])   # Sends prompts/list_changed notification
```

Notifications are only sent when these operations occur within an active MCP request context (e.g., when called from within a tool or other MCP operation). Operations performed during server initialization do not trigger notifications.

## Duplicate Handling

<VersionBadge version="2.1.0" />

Configure how the server handles attempts to register multiple prompts with the same name using the `on_duplicate_prompts` setting:

```python
from fastmcp import FastMCP

mcp = FastMCP(
    name="PromptServer",
    on_duplicate_prompts="error"  # Raise an error if a prompt name is duplicated
)
```

| Behavior | Description |
| :------- | :---------- |
| `"warn"` (default) | Logs a warning, new prompt replaces old |
| `"error"` | Raises `ValueError`, prevents duplicate registration |
| `"replace"` | Silently replaces existing prompt |
| `"ignore"` | Keeps original prompt, ignores new registration |

## Versioning

<VersionBadge version="3.0.0" />

Prompts support versioning, allowing you to maintain multiple implementations under the same name while clients automatically receive the highest version. See [Versioning](/servers/versioning) for complete documentation.

## Removing Prompts

Remove prompts dynamically with `remove_prompt()`:

```python
from fastmcp import FastMCP

mcp = FastMCP()

@mcp.prompt
def temporary_prompt() -> str:
    return "I won't be here long"

mcp.remove_prompt("temporary_prompt")
```
